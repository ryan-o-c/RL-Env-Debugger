{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f2b1ac-50d6-42d7-960c-b970912a4abb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done RL Import\n",
      "Preparing Environment\n",
      "Float32[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling ReinforcementLearning [158674fc-8238-5cab-b5ba-03dfc80d1318]\n",
      "└ @ Base loading.jl:1423\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# MyGrid\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                          Value |\n",
       "|:----------------- | ------------------------------:|\n",
       "| NumAgentStyle     |                  SingleAgent() |\n",
       "| DynamicStyle      |                   Sequential() |\n",
       "| InformationStyle  |           PerfectInformation() |\n",
       "| ChanceStyle       |                Deterministic() |\n",
       "| RewardStyle       |                   StepReward() |\n",
       "| UtilityStyle      |                   GeneralSum() |\n",
       "| ActionStyle       |                FullActionSet() |\n",
       "| StateStyle        | Observation{Vector{Float32}}() |\n",
       "| DefaultStateStyle | Observation{Vector{Float32}}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## State Space\n",
       "\n",
       "`Space{Vector{Interval{Int64, Closed, Closed}}}(Interval{Int64, Closed, Closed}[Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50)])`\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`Base.OneTo(25)`\n",
       "\n",
       "## Current State\n",
       "\n",
       "```\n",
       "Float32[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "```\n"
      ],
      "text/plain": [
       "# MyGrid\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                          Value |\n",
       "|:----------------- | ------------------------------:|\n",
       "| NumAgentStyle     |                  SingleAgent() |\n",
       "| DynamicStyle      |                   Sequential() |\n",
       "| InformationStyle  |           PerfectInformation() |\n",
       "| ChanceStyle       |                Deterministic() |\n",
       "| RewardStyle       |                   StepReward() |\n",
       "| UtilityStyle      |                   GeneralSum() |\n",
       "| ActionStyle       |                FullActionSet() |\n",
       "| StateStyle        | Observation{Vector{Float32}}() |\n",
       "| DefaultStateStyle | Observation{Vector{Float32}}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## State Space\n",
       "\n",
       "`Space{Vector{Interval{Int64, Closed, Closed}}}(Interval{Int64, Closed, Closed}[Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50), Interval{Int64, Closed, Closed}(0, 50)])`\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`Base.OneTo(25)`\n",
       "\n",
       "## Current State\n",
       "\n",
       "```\n",
       "Float32[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "```\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ReinforcementLearning, Intervals, Flux\n",
    "\n",
    "const RLBase = ReinforcementLearningBase\n",
    "\n",
    "println(\"Done RL Import\")\n",
    "\n",
    "Base.@kwdef mutable struct MyGrid <: AbstractEnv\n",
    "    N::Int\n",
    "    obs::Vector{Float32}\n",
    "    max_steps::Int    \n",
    "    \n",
    "    rewards::Float32\n",
    "    done::Bool \n",
    "    t::Int\n",
    "end\n",
    "\n",
    "function MyGrid(; n)\n",
    "    img = zeros(Float32, n,n)\n",
    "    vect = ones(Float32, 3)\n",
    "    obs = vcat(vect,vec(img))\n",
    "    println(obs)\n",
    "    \n",
    "\tMyGrid(n, obs, 10, 0, false, 0)\n",
    "end\n",
    "\n",
    "RLBase.action_space(env::MyGrid) = Base.OneTo(25)\n",
    "\n",
    "RLBase.legal_action_space(env::MyGrid) = legal_action_space_mask(env)\n",
    "\n",
    "function RLBase.legal_action_space_mask(env::MyGrid)\n",
    "\tmask = Vector(undef, 25)\n",
    "\tfill!(mask, true)\n",
    "\n",
    "    mask_index = Base.rand((1:25))\n",
    "\tmask[mask_index] = false\n",
    "\treturn mask\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function (env::MyGrid)(action) #This function takes the action, makes the environment step, and gives reward\n",
    "    \n",
    "    env.obs[action[1]] = 6 #action[1] avoids some strange error I don't understand\n",
    "    \n",
    "    env.rewards+=1\n",
    "    \n",
    "    env.t+=1\n",
    "    #Max steps check\n",
    "    if env.t >= env.max_steps\n",
    "        env.done = true\n",
    "    end\n",
    "end\n",
    "\n",
    "RLBase.state(env::MyGrid, ::Observation{Vector{Float32}}) = env.obs\n",
    "RLBase.state_space(env::MyGrid, ::Observation{Vector{Float32}}) = Space(fill( Interval{Int64}(0, (10*env.N) ) , (env.N^2+3)))\n",
    "\n",
    "RLBase.is_terminated(env::MyGrid) = env.done\n",
    "\n",
    "function RLBase.reset!(env::MyGrid)\n",
    "    #Reset Counter and rewards (and termination variable)\n",
    "    env.t = 0\n",
    "    env.rewards = 0\n",
    "    env.done = false    \n",
    "    #Reset State\n",
    "    img = zeros(env.N,env.N)\n",
    "    vect = ones(3)\n",
    "    env.obs = vcat(vect,vec(img))\n",
    "end;\n",
    "\n",
    "RLBase.reward(env::MyGrid) = env.rewards\n",
    "\n",
    "RLBase.NumAgentStyle(::MyGrid) = SINGLE_AGENT\n",
    "RLBase.DynamicStyle(::MyGrid) = SEQUENTIAL\n",
    "RLBase.ActionStyle(::MyGrid) = FULL_ACTION_SET\n",
    "RLBase.InformationStyle(::MyGrid) = PERFECT_INFORMATION\n",
    "\n",
    "RLBase.StateStyle(::MyGrid) = Observation{Vector{Float32}}()\n",
    "\n",
    "RLBase.RewardStyle(::MyGrid) = STEP_REWARD\n",
    "RLBase.UtilityStyle(::MyGrid) = GENERAL_SUM\n",
    "RLBase.ChanceStyle(::MyGrid) = DETERMINISTIC\n",
    "\n",
    "println(\"Preparing Environment\")\n",
    "N=5\n",
    "env = MyGrid(; n=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f8ee54-4350-40c1-bbbe-34645249b5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TotalBatchRewardPerEpisode([Float64[]], [0.0], true)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UPDATE_FREQ = 32\n",
    "N_ENV = 1\n",
    "input_size = 28\n",
    "\n",
    "agent = Agent(\n",
    "        policy = QBasedPolicy(\n",
    "            learner = A2CLearner(\n",
    "                approximator = ActorCritic(\n",
    "                    actor = Chain(\n",
    "                        Dense(input_size, 4*input_size, relu),\n",
    "                        Dense(4*input_size, 8*input_size, relu),\n",
    "                        Dense(8*input_size, 6*input_size, relu),\n",
    "                        Dense(6*input_size, 4*input_size, relu),\n",
    "                        Dense(4*input_size, 2*input_size, relu),\n",
    "                        Dense(2*input_size, 25),\n",
    "                    ),\n",
    "\n",
    "                    critic = Chain(\n",
    "                        Dense(input_size, 4*input_size, relu),\n",
    "                        Dense(4*input_size, 8*input_size, relu),\n",
    "                        Dense(8*input_size, 6*input_size, relu),\n",
    "                        Dense(6*input_size, 4*input_size, relu),\n",
    "                        Dense(4*input_size, 2*input_size, relu),\n",
    "                        Dense(2*input_size, 1),\n",
    "                    ),\n",
    "\n",
    "                    optimizer = ADAM(1e-3),\n",
    "                ),\n",
    "                γ = 0.99f0,\n",
    "                actor_loss_weight = 1.0f0,\n",
    "                critic_loss_weight = 0.5f0,\n",
    "                entropy_loss_weight = 0.001f0,\n",
    "                update_freq = UPDATE_FREQ,\n",
    "            ),\n",
    "\n",
    "            #explorer = BatchExplorer(GumbelSoftmaxExplorer()),\n",
    "            explorer=EpsilonGreedyExplorer(\n",
    "                kind=:exp,\n",
    "                ϵ_stable=0.01,\n",
    "                decay_steps=500,\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "\n",
    "\t    trajectory = CircularArraySARTTrajectory(;\n",
    "            capacity = UPDATE_FREQ,\n",
    "            state = Matrix{Float32} => (input_size, N_ENV),\n",
    "            action = Vector{Int} => (N_ENV,),\n",
    "            reward = Vector{Float32} => (N_ENV,),\n",
    "            terminal = Vector{Bool} => (N_ENV,),\n",
    "        ),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "hook = TotalBatchRewardPerEpisode(N_ENV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecb200d7-3196-4d75-aebe-27bada78b5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  25%|██████████▎                              |  ETA: 0:00:26\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values: Float32[-0.0038848114, -0.032028243, 0.017632825, -0.10160909, 0.036231592, -0.00055729167, 0.036761574, -0.0018544598, -0.020733155, 0.031485848, 0.0010244212, -0.049003795, 0.05508644, -0.07202485, -0.020319697, 0.022446275, -0.020134708, 0.04001557, -0.021725155, 0.11125428, -0.022910202, -0.004275955, -0.013713145, -0.009959723, 0.031443264] and mask: Any[true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.14228946, -0.11814363, -0.0008185971, -0.2064806, 0.1050148, -0.044275798, 0.12893558, -0.090099104, -0.11713499, -0.067914784, -0.057469904, -0.017017415, 0.10286204, -0.08789596, 0.028185278, -0.094691284, 0.11457257, 0.20240201, -0.08254326, 0.23744449, 0.03208153, -0.035807293, -0.047383066, -0.0770152, -0.03638997] and mask: Any[true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.14228946, -0.11814363, -0.0008185971, -0.2064806, 0.1050148, -0.044275798, 0.12893558, -0.090099104, -0.11713499, -0.067914784, -0.057469904, -0.017017415, 0.10286204, -0.08789596, 0.028185278, -0.094691284, 0.11457257, 0.20240201, -0.08254326, 0.23744449, 0.03208153, -0.035807293, -0.047383066, -0.0770152, -0.03638997] and mask: Any[true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[-0.07871237, -0.2053538, -0.0066061895, -0.45899308, 0.18573046, -0.06605243, 0.26327777, -0.093243666, -0.005219579, -0.03175695, -0.043477785, -0.092232965, 0.18727773, -0.26220885, 0.07490227, -0.16332975, 0.08629146, 0.21315765, -0.1276929, 0.42979482, -0.043115262, -0.024254669, -0.099884845, -0.021868177, -0.024266021] and mask: Any[true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.11802845, -0.19954365, 0.034926146, -0.39824805, 0.22551061, 0.015513063, 0.28088728, -0.13025837, -0.07456359, -0.048136164, -0.09863743, -0.07958489, 0.22485903, -0.22918868, 0.04242193, -0.25795928, 0.34504288, 0.23327857, -0.17392163, 0.53631, 0.09001959, 0.027550979, -0.12778838, -0.108429655, -0.08092596] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.25406778, -0.4376185, -0.10377079, -0.39461353, 0.37578914, -0.15793508, 0.25994432, -0.3691276, 0.0034569523, 0.028120035, -0.033784088, -0.02820172, 0.42453143, -0.3817397, -0.038264558, -0.20774902, 0.27545658, 0.25483635, -0.14290415, 0.56246644, 0.12454559, -0.19639967, -0.1994678, 0.020978134, 0.075881034] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.10761608, -0.39950544, -0.061225384, -0.46002203, 0.48037416, -0.18374468, 0.3610244, -0.37277526, -0.099699825, 0.0011185915, 0.04177723, -0.12635483, 0.31609958, -0.46066058, 0.24143592, -0.146066, 0.13276915, 0.22134015, -0.119693615, 0.8179967, 0.10259275, -0.13732843, -0.30210543, 0.052586496, 0.074454315] and mask: Any[true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.1775842, -0.6914509, -0.10360214, -0.6185423, 0.44621584, -0.44506526, 0.3435207, -0.38363498, 0.14322895, 0.34484148, 0.035499305, -0.19945574, 0.606135, -0.39103454, 0.3607292, -0.19916008, 0.0943299, 0.30862036, -0.3500398, 0.9343138, 0.08566761, -0.39137167, -0.41368434, -0.027863007, 0.034050964] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true] \n",
      "values: Float32[0.34418914, -0.71541995, -0.16319638, -0.83479637, 0.4180257, -0.46171564, 0.41314685, -0.31123364, 0.04024568, 0.123785526, -0.18626806, -0.43214425, 0.520119, -0.35226056, 0.5688961, -0.31145287, 0.3485957, 0.29131725, -0.51744664, 1.1754014, 0.045274686, -0.3728759, -0.35526082, 0.24697553, 0.3579909] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.4747395, -0.56841624, -0.013784603, -0.8963649, 0.39473143, -0.25383005, 0.59718853, -0.21255323, -0.1860566, 0.10489966, -0.025549302, -0.4844626, 0.3999643, -0.50495535, 0.25563186, -0.26498437, 0.5126934, 0.4356991, -0.47367507, 1.1575153, 0.29180518, -0.27946526, -0.3640866, 0.21243237, 0.34888136] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[-0.0038848114, -0.032028243, 0.017632825, -0.10160909, 0.036231592, -0.00055729167, 0.036761574, -0.0018544598, -0.020733155, 0.031485848, 0.0010244212, -0.049003795, 0.05508644, -0.07202485, -0.020319697, 0.022446275, -0.020134708, 0.04001557, -0.021725155, 0.11125428, -0.022910202, -0.004275955, -0.013713145, -0.009959723, 0.031443264] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true] \n",
      "values: Float32[0.07794846, -0.25954098, -0.08235839, -0.24175812, 0.2316204, -0.12241538, 0.073852144, -0.19976297, 0.026011214, 0.11805689, 0.04571652, -0.03072486, 0.2930877, -0.21938132, 0.117098145, -0.1374655, -0.010371197, 0.15447208, -0.0622822, 0.21968572, -0.020773795, -0.3030373, -0.14724414, 0.14685431, 0.0696744] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.37379944, -0.41377982, -0.14201225, -0.29532307, 0.25354263, -0.044263426, 0.24070832, -0.18864058, 0.044673137, 0.13912188, 0.0129105095, -0.13129364, 0.33525473, -0.3305957, 0.25984573, -0.2565231, 0.26147962, 0.25131655, -0.22501156, 0.5015926, 0.124400094, -0.21285002, -0.17203209, 0.11593481, 0.094742596] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.31915063, -0.43184417, 0.0104146125, -0.40441325, 0.29867682, -0.16539265, 0.27117702, -0.17638329, -0.09014855, -0.066760264, -0.10633477, -0.21050823, 0.3121049, -0.22974922, 0.254597, -0.29449305, 0.29746595, 0.22065665, -0.29296362, 0.5286968, 0.12643394, -0.17665169, -0.17787674, 0.1742761, 0.1267249] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.36155275, -0.48855758, 0.0152245965, -0.48652983, 0.47832733, -0.14901528, 0.2037169, -0.31889164, -0.41023496, -0.0047260374, 0.0142962355, -0.19063558, 0.4543483, -0.35499594, 0.15909277, -0.3016674, 0.12519518, 0.19647768, 0.035843376, 0.5612999, 0.27271023, -0.31222954, -0.36617795, 0.36234143, 0.32776937] and mask: Any[true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.2846627, -0.56349653, -0.23190567, -0.5432248, 0.6184787, -0.07819917, 0.28659022, -0.3098632, -0.33650035, 0.0704437, -0.040170327, -0.1879131, 0.6286363, -0.5505278, 0.0714944, -0.42455816, 0.2546824, 0.2405242, -0.05570935, 0.6963077, 0.21090934, -0.27312285, -0.36558607, 0.4642062, 0.48224792] and mask: Any[true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.69264483, -0.662352, -0.14567667, -0.53686, 0.7751894, -0.09595687, 0.30053207, -0.3978915, -0.25827548, -0.077388875, 0.10301915, -0.12371084, 0.5243845, -0.34942508, 0.21439213, -0.12846956, 0.51961166, 0.3062187, -0.20227604, 0.78397036, 0.3814642, -0.50640804, -0.47663075, 0.5172794, 0.39728796] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.69264483, -0.662352, -0.14567667, -0.53686, 0.7751894, -0.09595687, 0.30053207, -0.3978915, -0.25827548, -0.077388875, 0.10301915, -0.12371084, 0.5243845, -0.34942508, 0.21439213, -0.12846956, 0.51961166, 0.3062187, -0.20227604, 0.78397036, 0.3814642, -0.50640804, -0.47663075, 0.5172794, 0.39728796] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true] \n",
      "values: Float32[0.8028318, -0.9945746, -0.37637094, -0.6374128, 0.8481626, 0.13002202, 0.43736175, -0.47820008, 0.050850734, -0.083183795, 0.18312861, -0.34103584, 0.5107386, -0.4745888, 0.03581167, -0.275456, 0.74056077, 0.59939456, -0.69336015, 0.98513746, 0.37755087, -0.56974626, -0.52215517, 0.36878994, 0.5524881] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true] \n",
      "values: Float32[0.81128865, -1.1069245, -0.59740186, -0.83157563, 0.8644232, 0.013340052, 0.70095325, -0.44888112, 0.097431265, 0.07919579, 0.14920993, -0.27746743, 0.36466616, -0.673504, 0.25436565, -0.2304671, 0.85336, 0.6740454, -0.70010656, 1.2448735, 0.5538774, -0.5365956, -0.6028976, 0.45199198, 0.68636703] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true] \n",
      "values: Float32[-0.0038848114, -0.032028243, 0.017632825, -0.10160909, 0.036231592, -0.00055729167, 0.036761574, -0.0018544598, -0.020733155, 0.031485848, 0.0010244212, -0.049003795, 0.05508644, -0.07202485, -0.020319697, 0.022446275, -0.020134708, 0.04001557, -0.021725155, 0.11125428, -0.022910202, -0.004275955, -0.013713145"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  50%|████████████████████▌                    |  ETA: 0:01:02\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", -0.009959723, 0.031443264] and mask: Any[true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[-0.038415164, -0.044313733, -0.0020383564, -0.46849522, 0.15079787, -0.084743224, 0.35165018, 0.046136394, 0.031342324, 0.036070082, -0.0605635, -0.17892462, 0.19221704, -0.1866836, -0.11397059, -0.08862956, 0.17589338, 0.29528287, -0.13907135, 0.3665968, -0.013234453, 0.10649144, 0.0070157903, 0.1757529, -0.04392179] and mask: Any[true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.13072672, -0.16501029, 0.024486931, -0.56495017, 0.16458873, -0.15651307, 0.31735715, -0.06400016, 0.053914215, 0.10384582, 0.07348574, -0.20582813, 0.32547018, -0.20267855, 0.10385047, -0.20534365, 0.13624178, 0.19607197, -0.14817892, 0.48519084, 0.005649657, -0.050482407, -0.021857636, 0.27750567, 0.093482256] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.16767521, -0.43536487, -0.13149062, -0.7204921, 0.27916536, -0.28552836, 0.4122358, -0.18472248, 0.15442212, 0.13276128, 0.12846272, -0.1837038, 0.36387601, -0.13732147, -0.004548705, -0.17934342, 0.16164856, 0.37835446, -0.3421147, 0.7373841, 0.07248281, -0.20605175, -0.14550805, 0.0033348647, -0.08810848] and mask: Any[true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.16767521, -0.43536487, -0.13149062, -0.7204921, 0.27916536, -0.28552836, 0.4122358, -0.18472248, 0.15442212, 0.13276128, 0.12846272, -0.1837038, 0.36387601, -0.13732147, -0.004548705, -0.17934342, 0.16164856, 0.37835446, -0.3421147, 0.7373841, 0.07248281, -0.20605175, -0.14550805, 0.0033348647, -0.08810848] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.18788674, -0.59341574, -0.29813766, -0.8585714, 0.4276862, -0.2534258, 0.33828387, -0.39335707, 0.23194084, 0.26200628, 0.17833976, -0.24297532, 0.5757882, -0.33009455, -0.1564549, -0.17134091, 0.10439785, 0.3969184, -0.35007313, 0.9904487, 0.2606321, -0.14378817, -0.15851751, -0.082925506, 0.0078085135] and mask: Any[true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.28494844, -0.39469784, -0.29024127, -0.880498, 0.67052555, -0.14175424, 0.25207964, -0.42721882, 0.12082869, 0.14969528, 0.1171339, -0.42420608, 0.569609, -0.3098432, -0.13873895, -0.20001973, 0.26254803, 0.26290852, -0.3010752, 1.0885793, 0.21425588, -0.04912369, -0.10775534, 0.056759696, 0.003509315] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.15016389, -0.4830334, -0.40042108, -0.96556425, 0.5402741, -0.06813672, 0.50856954, -0.27145246, 0.041875377, 0.004178752, 0.100487545, -0.26276666, 0.37586588, -0.35718682, -0.057142705, -0.23610719, 0.28333414, 0.534441, -0.2973378, 1.2789509, 0.2116997, 0.13562696, -0.10925915, 0.074165404, -0.07934762] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true] \n",
      "values: Float32[-0.03612852, -0.2984443, -0.2800507, -1.0624131, 0.5724806, -0.07021192, 0.63896716, -0.1570815, -0.00726929, 0.019200675, -0.10214359, -0.50909895, 0.41472724, -0.606673, -0.26456928, -0.25426108, 0.3524039, 0.55846095, -0.27817014, 1.2802682, 0.22658026, 0.42493844, -0.027386652, 0.21644127, 0.030510772] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true] \n",
      "values: Float32[0.04787332, -0.53181934, -0.3090208, -1.1785419, 0.39261052, -0.3182052, 0.72345537, -0.12249861, 0.046326127, 0.19849174, -0.030987808, -0.16451097, 0.4121104, -0.41503936, 0.08523406, -0.16147941, 0.29057035, 0.6110768, -0.43136242, 1.2767899, 0.13326843, 0.17493288, -0.29075855, 0.19603167, -0.01752568] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true] \n",
      "values: Float32[-0.0038848114, -0.032028243, 0.017632825, -0.10160909, 0.036231592, -0.00055729167, 0.036761574, -0.0018544598, -0.020733155, 0.031485848, 0.0010244212, -0.049003795, 0.05508644, -0.07202485, -0.020319697, 0.022446275, -0.020134708, 0.04001557, -0.021725155, 0.11125428, -0.022910202, -0.004275955, -0.013713145, -0.009959723, 0.031443264] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false] \n",
      "values: Float32[0.0027568974, -0.29073322, -0.10631363, -0.3542953, 0.27294677, -0.02681061, 0.13113374, -0.10420607, 0.044444446, 0.15061301, 0.0796126, -0.007147381, 0.22683212, -0.23489879, -0.06055313, 0.08424592, -0.06324603, 0.2623203, -0.015211423, 0.54137635, 0.0287111, -0.095295124, -0.06643104, -0.028401999, 0.12724255] and mask: Any[true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.1225727, -0.35690233, -0.12174308, -0.46560365, 0.34056106, -0.1154664, 0.1492903, -0.10611523, 0.18782003, 0.42238492, -0.004988938, -0.037392173, 0.5860388, -0.44752494, -0.09865407, 0.09256292, -0.03207416, 0.3199167, -0.03587334, 0.7407551, 0.08677668, -0.09725409, -0.064438075, 0.115432225, -0.039247233] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.1249568, -0.51436305, -0.062386118, -0.4328946, 0.3664468, -0.22026277, 0.10714301, -0.16389023, -0.012058599, 0.44766733, -0.026841326, -0.14586677, 0.6962114, -0.26258633, -0.14927946, 0.07646861, -0.018485676, 0.2681149, -0.027041297, 0.92543215, 0.31777614, -0.0053998483, -0.18484086, -0.06757517, -0.17231342] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.11253433, -0.5665389, -0.11610908, -0.4199157, 0.24491484, -0.081189446, 0.34796584, -0.20603396, 0.08294372, 0.30324176, 0.13378817, -0.10979416, 0.36663282, -0.3621775, -0.09134247, -0.19091061, 0.19303857, 0.34339553, -0.26154044, 0.79614687, 0.23597367, -0.08406151, -0.24722555, -0.00012283202, 0.03511625] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true] \n",
      "values: Float32[0.11253433, -0.5665389, -0.11610908, -0.4199157, 0.24491484, -0.081189446, 0.34796584, -0.20603396, 0.08294372, 0.30324176, 0.13378817, -0.10979416, 0.36663282, -0.3621775, -0.09134247, -0.19091061, 0.19303857, 0.34339553, -0.26154044, 0.79614687, 0.23597367, -0.08406151, -0.24722555, -0.00012283202, 0.03511625] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true] \n",
      "values: Float32[0.11970142, -0.6256018, -0.18265839, -0.52838683, 0.39239934, -0.124556005, 0.37318715, -0.31682995, 0.033264685, 0.14565107, 0.14669709, -0.018914064, 0.290177, -0.32315865, -0.012549655, -0.35329556, 0.2156696, 0.4269558, -0.23108597, 0.87477106, 0.1637643, -0.059268393, -0.3413004, 0.04036456, 0.0084966505] and mask: Any[true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[-0.08565501, -0.5269303, -0.12321259, -0.7513724, 0.34822795, -0.09561263, 0.6508623, -0.060548056, -0.076385394, 0.124400884, -0.0026095489, -0.15894161, 0.2059827, -0.48644486, 0.25149915, -0.28749952, 0.16112629, 0.44715574, -0.1492624, 1.1314548, 0.059585154, 0.0034270263, -0.30094105, 0.3088654, 0.02591741] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true] \n",
      "values: Float32[-0.08565501, -0.5269303, -0.12321259, -0.7513724, 0.34822795, -0.09561263, 0.6508623, -0.060548056, -0.076385394, 0.124400884, -0.0026095489, -0.15894161, 0.2059827, -0.48644486, 0.25149915, -0.28749952, 0.16112629, 0.44715574, -0.1492624, 1.1314548, 0.059585154, 0.0034270263, -0.30094105, 0.3088654, 0.02591741] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true] \n",
      "values: Float32[-0.08565501, -0.5269303, -0.12321259, -0.7513724, 0.34822795, -0.09561263, 0.6508623, -0.060548056, -0.076385394, 0.124400884, -0.0026095489, -0.15894161, 0.2059827, -0.48644486, 0.25149915, -0.28749952, 0.16112629, 0.44715574, -0.1492624, 1.1314548, 0.059585154, 0.0034270263, -0.30094105, 0.3088654, 0.02591741] and mask: Any[true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.0037131603, -0.01105803, -0.009797284, -0.07409933, 0.036252867, 0.0077214893, 0.025779953, 0.010181207, -0.041542538, 0.034855276, -0.009655991, -0.034687027, 0.052237134, -0.062160585, -0.0179594, 0.012681356, 0.01790767, 0.043749746, -0.021116406, 0.11418479, 0.004198702, 0.03150711, -0.027607363, 0.00033786986, 0.0024545542] and mask: Any[true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true] \n",
      "values: Float32[0.13689405, -0.23348668, -0.07262974, -0.23600987, 0.16057149, -0.20179433, 0.07006531, -0.16497648, 0.10794134, 0.0639976, -0.12044368, -0.17675257, 0.21484911, -0.011266831, -0.020980362, -0.17133856, 0.13957776, 0.059669252, -0.19318767, 0.2599507, 0.018828344, -0.10508982, -0.096976414, 0.014689187, 0.01139293] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true] \n",
      "values: Float32[-0.06736562, -0.14842498, -0.03438756, -0.2348835, 0.19270504, -0.06881056, 0.06740674, -0.13019112, 0.09400712, 0.10236878, -0.114360444, -0.24241893, 0.17329161, -0.14359772, -0.08873647, -0.14410512, 0.04276317, 0.0986805, -0.17130606, 0.33509204, -0.094900094, -0.05302921, -0.07780004, 0.046892297, 0.07059874] and mask: Any[true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true] \n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: objects of type Vector{Float32} are not callable\nUse square brackets [] for indexing an Array.",
     "output_type": "error",
     "traceback": [
      "MethodError: objects of type Vector{Float32} are not callable\nUse square brackets [] for indexing an Array.",
      "",
      "Stacktrace:",
      "  [1] (::Base.var\"#260#261\"{Vector{Float32}})(::Pair{Int64, Any})",
      "    @ Base ./reduce.jl:803",
      "  [2] MappingRF",
      "    @ ./reduce.jl:95 [inlined]",
      "  [3] _foldl_impl",
      "    @ ./reduce.jl:58 [inlined]",
      "  [4] foldl_impl(op::Base.MappingRF{Base.var\"#260#261\"{Vector{Float32}}, Base.BottomRF{typeof(Base._rf_findmax)}}, nt::Base._InitialValue, itr::Base.Pairs{Int64, Any, LinearIndices{1, Tuple{Base.OneTo{Int64}}}, Vector{Any}})",
      "    @ Base ./reduce.jl:48",
      "  [5] mapfoldl_impl(f::Base.var\"#260#261\"{Vector{Float32}}, op::typeof(Base._rf_findmax), nt::Base._InitialValue, itr::Base.Pairs{Int64, Any, LinearIndices{1, Tuple{Base.OneTo{Int64}}}, Vector{Any}})",
      "    @ Base ./reduce.jl:44",
      "  [6] mapfoldl(f::Function, op::Function, itr::Base.Pairs{Int64, Any, LinearIndices{1, Tuple{Base.OneTo{Int64}}}, Vector{Any}}; init::Base._InitialValue)",
      "    @ Base ./reduce.jl:162",
      "  [7] mapfoldl(f::Function, op::Function, itr::Base.Pairs{Int64, Any, LinearIndices{1, Tuple{Base.OneTo{Int64}}}, Vector{Any}})",
      "    @ Base ./reduce.jl:162",
      "  [8] findmax(f::Vector{Float32}, domain::Vector{Any})",
      "    @ Base ./reduce.jl:803",
      "  [9] (::EpsilonGreedyExplorer{:exp, false, Random._GLOBAL_RNG})(values::Vector{Float32}, mask::Vector{Any})",
      "    @ ReinforcementLearningCore ~/.julia/packages/ReinforcementLearningCore/s9XPF/src/policies/q_based_policies/explorers/epsilon_greedy_explorer.jl:129",
      " [10] (::QBasedPolicy{A2CLearner{ActorCritic{Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}}, EpsilonGreedyExplorer{:exp, false, Random._GLOBAL_RNG}})(env::MyGrid, #unused#::FullActionSet, #unused#::Base.OneTo{Int64})",
      "    @ ReinforcementLearningCore ~/.julia/packages/ReinforcementLearningCore/s9XPF/src/policies/q_based_policies/q_based_policy.jl:25",
      " [11] QBasedPolicy",
      "    @ ~/.julia/packages/ReinforcementLearningCore/s9XPF/src/policies/q_based_policies/q_based_policy.jl:22 [inlined]",
      " [12] Agent",
      "    @ ~/.julia/packages/ReinforcementLearningCore/s9XPF/src/policies/agents/agent.jl:24 [inlined]",
      " [13] _run(policy::Agent{QBasedPolicy{A2CLearner{ActorCritic{Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}}, EpsilonGreedyExplorer{:exp, false, Random._GLOBAL_RNG}}, CircularArraySARTTrajectory{NamedTuple{(:state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float32, 3, Array{Float32, 3}}, CircularArrayBuffers.CircularArrayBuffer{Int64, 2, Matrix{Int64}}, CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}}, env::MyGrid, stop_condition::StopAfterEpisode{ProgressMeter.Progress}, hook::TotalBatchRewardPerEpisode)",
      "    @ ReinforcementLearningCore ~/.julia/packages/ReinforcementLearningCore/s9XPF/src/core/run.jl:27",
      " [14] run(policy::Agent{QBasedPolicy{A2CLearner{ActorCritic{Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}}, EpsilonGreedyExplorer{:exp, false, Random._GLOBAL_RNG}}, CircularArraySARTTrajectory{NamedTuple{(:state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float32, 3, Array{Float32, 3}}, CircularArrayBuffers.CircularArrayBuffer{Int64, 2, Matrix{Int64}}, CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}}, env::MyGrid, stop_condition::StopAfterEpisode{ProgressMeter.Progress}, hook::TotalBatchRewardPerEpisode)",
      "    @ ReinforcementLearningCore ~/.julia/packages/ReinforcementLearningCore/s9XPF/src/core/run.jl:10",
      " [15] top-level scope",
      "    @ In[3]:1",
      " [16] eval",
      "    @ ./boot.jl:373 [inlined]",
      " [17] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1196"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: both Losses and NNlib export \"ctc_loss\"; uses of it in module Flux must be qualified\n"
     ]
    }
   ],
   "source": [
    "run(agent, env, StopAfterEpisode(8), hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc3a6669-007f-4108-b547-d5f3b20a8903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values length: 25 and mask length: 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [-0.06736562, -0.14842498, -0.03438756, -0.2348835, 0.19270504, -0.06881056, 0.06740674, -0.13019112, 0.09400712, 0.10236878, -0.114360444, -0.24241893, 0.17329161, -0.14359772, -0.08873647, -0.14410512, 0.04276317, 0.0986805, -0.17130606, 0.33509204, -0.094900094, -0.05302921, -0.07780004, 0.046892297, 0.07059874]\n",
    "mask = [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true]\n",
    "\n",
    "vals_len = length(values)\n",
    "\n",
    "mask_len = length(mask)\n",
    "\n",
    "\n",
    "println(\"values length: \", vals_len, \" and mask length: \", mask_len)\n",
    "\n",
    "findmax(values, mask)[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b60adb4-1455-4e85-b76c-75d7db4b3261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values length: 64 and mask length: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is a similar bug test for my \"production\" version of the environment that I use in my research. Action space is much larger (64)\n",
    "#Seems like it should be the same error!\n",
    "\n",
    "values = [-0.018166097470102248, -0.05312329404601712, -0.11821760730890844, 0.01130529832199928, 0.25495336620659376, 0.03688280274304784, 0.24376921960025238, 0.09219057380660353, 0.13532862570075035, -0.006394795989184387, 0.06804521432895054, -0.10223188563086141, 0.09034899740849847, -0.014090588857831439, 0.10504844247607419, -0.1010042722516204, -0.06139492012262019, 0.04547940613530445, 0.14835828847573806, 0.17224788209978356, 0.022583950763336302, 0.09815816625439103, -0.1086762831646083, -0.04875057012926273, -0.004055656945551531, 0.0771577468229819, 0.28446659449818534, 0.05801666527334296, 0.012560477373359635, -0.020215410519104898, -0.17811680727261842, 0.0659528204220787, -0.1398748086613198, 0.0683758730845624, 0.1397017022419469, -0.09369770003150565, 0.005993454421915061, 0.0015033004316932636, -0.06735809777500537, 0.03484625372778246, -0.15758421574125123, 0.07659801068910996, -0.12459759486470504, -0.0419593543471892, -0.00940457689693222, -0.2681972368143283, 0.14750588128489334, 0.030406348586110007, -0.03335642103175048, 0.10261564895656809, -0.0047844669243396094, 0.0925932127099294, 0.03755944363783806, -0.07972708307755658, -0.09741959496801679, -0.03881579249499037, -0.07526886357099384, -0.1716122010795189, -0.01426435240576198, -0.11978894015708387, 0.009270593322248836, -0.12199733236932064, 0.11713120363075379, -0.03448852026738303]\n",
    "\n",
    "mask = [true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, true, true]\n",
    "\n",
    "vals_len = length(values)\n",
    "\n",
    "mask_len = length(mask)\n",
    "\n",
    "\n",
    "println(\"values length: \", vals_len, \" and mask length: \", mask_len)\n",
    "\n",
    "findmax(values, mask)[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c630bd5e-8669-46d3-b675-c97b5697b4e0",
   "metadata": {},
   "source": [
    "Old Code for complex state version of environment (Ignore!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b7c0a9f-6e74-4076-a31f-9cf576940d07",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TotalBatchRewardPerEpisode([Float64[]], [0.0], true)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UPDATE_FREQ = 32\n",
    "N_ENV = 1\n",
    "\n",
    "agent = Agent(\n",
    "        policy = PPOPolicy(\n",
    "            approximator = ActorCritic(\n",
    "                    actor = Chain(\n",
    "                                x -> ( reshape(x[4:28], (5,5,1,1)), x[1:3]), #Parallel expects a tuple input - very difficult to pass a tuple as state\n",
    "                                Parallel(vcat, \n",
    "                                        Chain(Conv((3,3), 1 => 1, relu; stride = 1, pad = 0),\n",
    "                                        Flux.flatten),\n",
    "\n",
    "                                        Chain(Dense(3, 6, relu), Dense(6, 3, relu), Dense(3, 1, relu)) ),\n",
    "                                Dense(10, 40, relu),\n",
    "                                Dense(40,80,relu),\n",
    "                                Dense(80,50,relu),\n",
    "                                Dense(50,25)),\n",
    "\n",
    "                    critic = Chain(\n",
    "                                x -> ( reshape(x[4:28], (5,5,1,1)), x[1:3]),\n",
    "                                Parallel(vcat, \n",
    "                                        Chain(Conv((3,3), 1 => 1, relu; stride = 1, pad = 0),\n",
    "                                        Flux.flatten),\n",
    "\n",
    "                                        Chain(Dense(3, 6, relu), Dense(6, 3, relu), Dense(3, 1, relu)) ),\n",
    "                                Dense(10, 40, relu),\n",
    "                                Dense(40,80,relu),\n",
    "                                Dense(80,50,relu),\n",
    "                                Dense(50,25,relu),\n",
    "                                Dense(25,5,relu),\n",
    "                                Dense(5,1)),\n",
    "            \n",
    "                optimizer = ADAM(1e-3),\n",
    "            ),\n",
    "            γ = 0.99f0,\n",
    "            λ = 0.95f0,\n",
    "            clip_range = 0.1f0,\n",
    "            max_grad_norm = 0.5f0,\n",
    "            n_epochs = 4,\n",
    "            n_microbatches = 4,\n",
    "            actor_loss_weight = 1.0f0,\n",
    "            critic_loss_weight = 0.5f0,\n",
    "            entropy_loss_weight = 0.001f0,\n",
    "            update_freq = UPDATE_FREQ,\n",
    "        ),\n",
    "        trajectory = PPOTrajectory(;\n",
    "            capacity = UPDATE_FREQ, \n",
    "            state = Matrix{Float32} => (28, N_ENV),\n",
    "            action = Vector{Int} => (N_ENV,),\n",
    "            action_log_prob = Vector{Float32} => (N_ENV,),\n",
    "            reward = Vector{Float32} => (N_ENV,),  \n",
    "            terminal = Vector{Bool} => (N_ENV,),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "#stop_condition = StopAfterStep(30000, is_show_progress=true)\n",
    "hook = TotalBatchRewardPerEpisode(N_ENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45a24388-252d-4358-b108-3e783c343514",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  25%|██████████▎                              |  ETA: 0:00:03\u001b[39m"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access 1-element view(::Matrix{Float32}, 1, :) with eltype Float32 at index [33]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 1-element view(::Matrix{Float32}, 1, :) with eltype Float32 at index [33]",
      "",
      "Stacktrace:",
      "  [1] throw_boundserror(A::SubArray{Float32, 1, Matrix{Float32}, Tuple{Int64, Base.Slice{Base.OneTo{Int64}}}, true}, I::Tuple{Int64})",
      "    @ Base ./abstractarray.jl:691",
      "  [2] checkbounds",
      "    @ ./abstractarray.jl:656 [inlined]",
      "  [3] getindex",
      "    @ ./subarray.jl:302 [inlined]",
      "  [4] _generalized_advantage_estimation!(advantages::SubArray{Float32, 1, Matrix{Float32}, Tuple{Int64, Base.Slice{Base.OneTo{Int64}}}, true}, rewards::SubArray{Float32, 1, Matrix{Float32}, Tuple{Int64, Vector{Int64}}, false}, values::SubArray{Float32, 1, Matrix{Float32}, Tuple{Int64, Base.Slice{Base.OneTo{Int64}}}, true}, γ::Float32, λ::Float32, terminal::SubArray{Bool, 1, Matrix{Bool}, Tuple{Int64, Vector{Int64}}, false})",
      "    @ ReinforcementLearningCore ~/.julia/packages/ReinforcementLearningCore/s9XPF/src/utils/base.jl:445",
      "  [5] _generalized_advantage_estimation!(advantages::Matrix{Float32}, rewards::CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, values::Matrix{Float32}, γ::Float32, λ::Float32, terminal::CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}, dims::Int64)",
      "    @ ReinforcementLearningCore ~/.julia/packages/ReinforcementLearningCore/s9XPF/src/utils/base.jl:425",
      "  [6] #generalized_advantage_estimation!#24",
      "    @ ~/.julia/packages/ReinforcementLearningCore/s9XPF/src/utils/base.jl:387 [inlined]",
      "  [7] #generalized_advantage_estimation#23",
      "    @ ~/.julia/packages/ReinforcementLearningCore/s9XPF/src/utils/base.jl:375 [inlined]",
      "  [8] _update!(p::PPOPolicy{ActorCritic{Chain{Tuple{var\"#9#11\", Parallel{typeof(vcat), Tuple{Chain{Tuple{Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, typeof(flatten)}}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}}}}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{var\"#10#12\", Parallel{typeof(vcat), Tuple{Chain{Tuple{Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, typeof(flatten)}}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}}}}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Distributions.Categorical{P} where P<:Real, Random._GLOBAL_RNG}, t::Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularArrayBuffer{Float32, 3, Array{Float32, 3}}, CircularArrayBuffers.CircularArrayBuffer{Int64, 2, Matrix{Int64}}, CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}})",
      "    @ ReinforcementLearningZoo ~/.julia/packages/ReinforcementLearningZoo/uNyVA/src/algorithms/policy_gradient/ppo.jl:244",
      "  [9] update!",
      "    @ ~/.julia/packages/ReinforcementLearningZoo/uNyVA/src/algorithms/policy_gradient/ppo.jl:210 [inlined]",
      " [10] (::Agent{PPOPolicy{ActorCritic{Chain{Tuple{var\"#9#11\", Parallel{typeof(vcat), Tuple{Chain{Tuple{Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, typeof(flatten)}}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}}}}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{var\"#10#12\", Parallel{typeof(vcat), Tuple{Chain{Tuple{Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, typeof(flatten)}}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}}}}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Distributions.Categorical{P} where P<:Real, Random._GLOBAL_RNG}, Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularArrayBuffer{Float32, 3, Array{Float32, 3}}, CircularArrayBuffers.CircularArrayBuffer{Int64, 2, Matrix{Int64}}, CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}})(stage::PreActStage, env::MyGrid, action::Vector{Int64})",
      "    @ ReinforcementLearningCore ~/.julia/packages/ReinforcementLearningCore/s9XPF/src/policies/agents/agent.jl:78",
      " [11] _run(policy::Agent{PPOPolicy{ActorCritic{Chain{Tuple{var\"#9#11\", Parallel{typeof(vcat), Tuple{Chain{Tuple{Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, typeof(flatten)}}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}}}}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{var\"#10#12\", Parallel{typeof(vcat), Tuple{Chain{Tuple{Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, typeof(flatten)}}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}}}}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Distributions.Categorical{P} where P<:Real, Random._GLOBAL_RNG}, Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularArrayBuffer{Float32, 3, Array{Float32, 3}}, CircularArrayBuffers.CircularArrayBuffer{Int64, 2, Matrix{Int64}}, CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}}, env::MyGrid, stop_condition::StopAfterEpisode{ProgressMeter.Progress}, hook::TotalBatchRewardPerEpisode)",
      "    @ ReinforcementLearningCore ~/.julia/packages/ReinforcementLearningCore/s9XPF/src/core/run.jl:29",
      " [12] run(policy::Agent{PPOPolicy{ActorCritic{Chain{Tuple{var\"#9#11\", Parallel{typeof(vcat), Tuple{Chain{Tuple{Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, typeof(flatten)}}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}}}}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{var\"#10#12\", Parallel{typeof(vcat), Tuple{Chain{Tuple{Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, typeof(flatten)}}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}}}}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Distributions.Categorical{P} where P<:Real, Random._GLOBAL_RNG}, Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularArrayBuffer{Float32, 3, Array{Float32, 3}}, CircularArrayBuffers.CircularArrayBuffer{Int64, 2, Matrix{Int64}}, CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}}, env::MyGrid, stop_condition::StopAfterEpisode{ProgressMeter.Progress}, hook::TotalBatchRewardPerEpisode)",
      "    @ ReinforcementLearningCore ~/.julia/packages/ReinforcementLearningCore/s9XPF/src/core/run.jl:10",
      " [13] top-level scope",
      "    @ In[36]:1",
      " [14] eval",
      "    @ ./boot.jl:373 [inlined]",
      " [15] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "run(agent, env, StopAfterEpisode(8), hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9255c-1ae5-4e04-bd16-948086c3e89e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
